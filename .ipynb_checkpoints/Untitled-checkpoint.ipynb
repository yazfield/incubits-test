{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, classification_report\n",
    "import pandas as pd\n",
    "from gensim.models import Doc2Vec\n",
    "import re\n",
    "import string\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BALANCE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Cleaning data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "training_text = pd.read_csv('data/training_text', sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n",
    "training_variants = pd.read_csv('data/training_variants')\n",
    "train = pd.merge(training_text, training_variants, on='ID')\n",
    "\n",
    "punct = []\n",
    "for c in list(string.punctuation):\n",
    "    if c in ['-', '%', '$']:\n",
    "        continue\n",
    "    punct += [c]\n",
    "punct += ['′', '–', '°']\n",
    "\n",
    "print('Cleaning data')\n",
    "\n",
    "model = Doc2Vec.load('data/doc2vec2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt):\n",
    "    txt = txt.strip().lower()\n",
    "    txt = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', txt)\n",
    "    txt = re.sub('\\[[0-9]+\\]', '', txt)\n",
    "    txt = re.sub('/', ' ', txt)\n",
    "    for p in punct:\n",
    "        txt = txt.replace(p, ' ')\n",
    "    txt = re.sub(' [0-9]+ ', ' ', txt)\n",
    "    return txt.strip()\n",
    "\n",
    "def show_prediction_result(classifier, X, y):\n",
    "    probas = classifier.predict_proba(X)\n",
    "    pred_indices = np.argmax(probas, axis=1)\n",
    "    classes = np.unique(y)\n",
    "    preds = classes[pred_indices]\n",
    "    print('Log loss: {}'.format(log_loss(y, probas)))\n",
    "    print(classification_report(y, preds))\n",
    "    \n",
    "def evaluate(classifier, X, y, X_test=None, y_test=None, t=False):\n",
    "    classifier.fit(X, y)\n",
    "    show_prediction_result(classifier, X, y)\n",
    "    if t\n",
    "        print('')\n",
    "        print('Test set:')\n",
    "        show_prediction_result(classifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing data\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing data')\n",
    "Xdoc = []\n",
    "for doc in train['Text'].apply(clean):\n",
    "    Xdoc.append(model.infer_vector(list(filter(None, doc.split()))))\n",
    "Xdoc = np.array(Xdoc)\n",
    "ydoc = train['Class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing data\n",
      "New data shape: (3780, 1000)\n"
     ]
    }
   ],
   "source": [
    "if BALANCE:\n",
    "    print('Balancing data')\n",
    "\n",
    "    ratios = {\n",
    "        7: 600,\n",
    "        4: 500,\n",
    "        1: 480,\n",
    "        2: 450\n",
    "    }\n",
    "    ros = ClusterCentroids(random_state=8, ratio=ratios)\n",
    "    Xdoc, ydoc = ros.fit_sample(Xdoc, ydoc)\n",
    "\n",
    "    ratios = {\n",
    "        6: 400,\n",
    "        5: 400,\n",
    "        3: 350,\n",
    "        9: 300,\n",
    "        8: 300\n",
    "    }\n",
    "    ros = SMOTE(random_state=8, ratio=ratios)\n",
    "    Xdoc, ydoc = ros.fit_sample(Xdoc, ydoc)\n",
    "    print('New data shape:', Xdoc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate() got an unexpected keyword argument 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c15af91ffbfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mBALANCE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate() got an unexpected keyword argument 't'"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "lr_clf = LogisticRegression(C=.8)\n",
    "\n",
    "if BALANCE:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xdoc, ydoc)\n",
    "    evaluate(lr_clf, X_train, y_train, X_test=X_test, y_test=y_test, t=True)\n",
    "else:\n",
    "    evaluate(lr_clf, Xdoc, ydoc)\n",
    "\n",
    "print('old: train 0.02666984817734259 1.00 test 1.878469765018703 0.74')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Loading data\n",
      "Vectorizing test data\n"
     ]
    }
   ],
   "source": [
    "print('Testing')\n",
    "print('Loading data')\n",
    "test_variants = pd.read_csv('data/test_variants')\n",
    "test_text = pd.read_csv('data/test_text', sep=\"\\|\\|\", engine=\"python\", skiprows=1,\n",
    "    names=[\"ID\", \"Text\"])\n",
    "test_y_data = pd.read_csv('data/stage1_solution_filtered.csv')\n",
    "test_data = pd.merge(test_text, test_variants, on='ID')\n",
    "test = test_data.loc[test_data['ID'].isin(test_y_data['ID'].values)]\n",
    "\n",
    "print('Vectorizing test data')\n",
    "Xt = []\n",
    "for doc in test['Text'].apply(clean):\n",
    "    Xt.append(model.infer_vector(list(filter(None, doc.split()))))\n",
    "Xt = np.array(Xt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = np.argmax(test_y_data.values[:, 1:], axis=1) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 700) (368,) 2\n"
     ]
    }
   ],
   "source": [
    "print(Xt.shape, yt.shape, yt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training full data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.8, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training full data')\n",
    "lr_clf.fit(Xdoc, ydoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n"
     ]
    }
   ],
   "source": [
    "print('Predicting')\n",
    "probas = lr_clf.predict_proba(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 9) [1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(probas.shape, np.unique(yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 3.5841476087919077\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.47      0.54        94\n",
      "          2       0.36      0.33      0.34        46\n",
      "          3       0.33      0.43      0.38         7\n",
      "          4       0.52      0.63      0.57        65\n",
      "          5       0.28      0.44      0.34        25\n",
      "          6       0.47      0.64      0.54        22\n",
      "          7       0.67      0.62      0.65       101\n",
      "          8       0.00      0.00      0.00         2\n",
      "          9       0.60      0.50      0.55         6\n",
      "\n",
      "avg / total       0.55      0.53      0.53       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_indices = np.argmax(probas, axis=1)\n",
    "classes = np.unique(ydoc)\n",
    "preds = classes[pred_indices]\n",
    "print('Log loss: {}'.format(log_loss(yt, probas)))\n",
    "print(classification_report(yt, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.apply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
